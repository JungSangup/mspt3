## [Appendix] Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì„±í•˜ê¸° ( with kubeadm )

<br>

kubeadm ë„êµ¬ë¥¼ ì´ìš©í•´ì„œ Kubernetes clusterë¥¼ êµ¬ì„±í•˜ëŠ” ì ˆì°¨ì…ë‹ˆë‹¤.  
ì´ ë¬¸ì„œëŠ” [Bootstrapping clusters with kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/) ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

<br>

**Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì„± ìˆœì„œ**

1. Node VM(Virtual machine) ì¤€ë¹„
2. Container runtime ì„¤ì¹˜
3. kubeadm, kubelet, kubectl ì„¤ì¹˜
4. Control-plane node êµ¬ì„±
5. (Worker) node êµ¬ì„±
6. Helm ì„¤ì¹˜
7. Ingress controller ì„¤ì¹˜ ë° êµ¬ì„±
8. Storage Class êµ¬ì„±

---

### í´ëŸ¬ìŠ¤í„° êµ¬ì„±

ì´ ê°€ì´ë“œëŠ” ì•„ë˜ì™€ ê°™ì€ êµ¬ì„±ìœ¼ë¡œ ì§„í–‰í•¨.

- Node êµ¬ì„± : Contol-plane node * 1 , (Worker) node * 2
- Node OS : Ubuntu Server 22.04 LTS
- Container runtime : containerd
- Kubernetes version : 1.29
- Ingress controller : ingress nginx
- Srorage Class : NFS, NFS provisioner

---

### 1. Node VM(Virtual machine) ì¤€ë¹„

Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì„±ì„ ìœ„í•œ Node VMë“¤ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.  

> VMì´ ì•„ë‹Œ ë‹¤ë¥¸ êµ¬ì„±(e.g. Bare metal server, PC, Single board computer etc.)ì„ ì´ìš©í•˜ëŠ” ê²½ìš° ì´ ë‹¨ê³„ëŠ” ìƒëµí•˜ë©´ ë©ë‹ˆë‹¤.  

ëª¨ë“  VM ë…¸ë“œëŠ” ì¸í„°ë„·ì— ì—°ê²°ë˜ì–´ ìˆê³ , Public IP Addressë¥¼ ê°€ì§„ êµ¬ì„±ìœ¼ë¡œ í•©ë‹ˆë‹¤.  
ì´ ê°€ì´ë“œëŠ” AWSì˜ EC2 Instanceë¥¼ ì´ìš©í•˜ëŠ” ê²½ìš°ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.  

> AWSì˜ Default VPCëŠ” Internet Gatewayë¥¼ ì´ìš©í•˜ì—¬ ì¸í„°ë„·ì— ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ì•„ë˜ì™€ ê°™ì´ ì„¸ ê°œì˜ VMì„ ì¤€ë¹„í•©ë‹ˆë‹¤.

| Node name        | OS                      | Node type | VPC         | Public IP | Storage |
|:---------------- |:-----------------------:| --------- |:-----------:| --------- | ------- |
| k8s-controlplane | Ubuntu Server 22.04 LTS | t3.medium | Default VPC | Enable    | 20GiB   |
| k8s-node01        | Ubuntu Server 22.04 LTS | t3.medium | Default VPC | Enable    | 20GiB   |
| k8s-node02        | Ubuntu Server 22.04 LTS | t3.medium | Default VPC | Enable    | 20GB    |

ì•„ë˜ëŠ” k8s-controlplane êµ¬ì„± ì˜ˆì‹œì´ë©°, k8s-node1ì™€ k8s-node2ëŠ” Nameë§Œ ë‹¤ë¥´ê²Œ í•˜ê³  ë‹¤ë¥¸ êµ¬ì„±ì€ ë™ì¼í•˜ê²Œ ì§„í–‰í•©ë‹ˆë‹¤.  

![](./img/k8s_bootstrapping_1.png)

![](./img/k8s_bootstrapping_2.png)
> **Key pair**ëŠ” SSH ì ‘ì†ì„ ìœ„í•´ í•„ìš”í•¨.

![](./img/k8s_bootstrapping_3.png)
> Inbound Security Group Ruleì€ SSH ì ‘ì†ì„ ìœ„í•œ MyIPë§Œ ìš°ì„  ì„¤ì •í•˜ê³ , ì¶”í›„ í•„ìš”í•œ ì„¤ì • ì¶”ê°€ ì˜ˆì •.

![](./img/k8s_bootstrapping_4.png)


---

### [Option] Swapoff

KubernetesëŠ” Swap ë©”ëª¨ë¦¬ë¥¼ ì§€ì›í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.  
ë”°ë¼ì„œ, Kubernetesë¥¼ êµ¬ì„±í•˜ë ¤ëŠ” ë…¸ë“œì—ì„œëŠ” Swap ì„¤ì •ì„ ëª¨ë‘ ë¹„í™œì„±í™” í•´ì•¼ í•©ë‹ˆë‹¤.
> ìµœê·¼ì—ëŠ” ì§€ì›í•˜ë ¤ëŠ” ì›€ì§ì„ì´ ìˆìŠµë‹ˆë‹¤. ( [Kubernetes 1.28: Beta support for using swap on Linux](https://kubernetes.io/blog/2023/08/24/swap-linux-beta/) )

ë¨¼ì € Swap ì„¤ì • í™•ì¸ì€ ë‹¤ìŒê³¼ ê°™ì´ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```bash
$ free --human
               total        used        free      shared  buff/cache   available
Mem:           3.8Gi       630Mi       123Mi       2.0Mi       3.0Gi       2.8Gi
Swap:             0B          0B          0B
$ swapon --summary
$
```
> ğŸ’» ëª…ë ¹ì–´
>```bash
>free --human
>```
>```bash
>swapon --summary
>```
> `free` ë˜ëŠ” `swapon` ëª…ë ¹ì–´ ì‚¬ìš©. (ìœ„ ì˜ˆì‹œëŠ” Swap ë¹„í™œì„±í™” ëœ ê²½ìš°ì„.)

ìœ„ ì˜ˆì‹œì²˜ëŸ¼ Swap ì´ ë¹„í™œì„±í™” ë˜ì–´ìˆëŠ” ê²½ìš°ì—ëŠ” ì´ ì ˆì°¨ë¥¼ ìƒëµí•˜ê³  ë‹¤ìŒ ì ˆì°¨(2. Container runtime ì„¤ì¹˜)ë¥¼ ë°”ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì´ Swapì„ ë¹„í™œì„±í™” í•©ë‹ˆë‹¤.  

ë¨¼ì €, í˜„ì¬ ì„¤ì •ëœ swap ë©”ëª¨ë¦¬ë¥¼ ë¹„í™œì„±í™” í•©ë‹ˆë‹¤. (swapoff)
```bash
$ sudo swapoff --all
```
> ğŸ’» ëª…ë ¹ì–´
>```bash
>sudo swapoff --all
>```

ê·¸ ë‹¤ìŒì€, OSê°€ ì¬ì‹œì‘ ë˜ë”ë¼ë„ swap êµ¬ì„±ì´ ë˜ì§€ ì•Šë„ë¡ ë‹¤ìŒê³¼ ê°™ì´ fstab íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
```bash
$ sudo sed -i '/ swap / s/^/#/' /etc/fstab
```
> ğŸ’» ëª…ë ¹ì–´
>```bash
>sudo sed -i '/ swap / s/^/#/' /etc/fstab
>```
> /etc/fstabíŒŒì¼ì—ì„œ swap ì„¤ì • ë¶€ë¶„ì„ ì°¾ì•„ì„œ comment out ì²˜ë¦¬(#) í•¨.


---

### 2. Container runtime ì„¤ì¹˜

ì¤€ë¹„ëœ Nodeì— Container runtime ì¤‘ í•˜ë‚˜ì¸ containerdë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.  
ì•„ë˜ ë‚´ìš©ì€ ëª¨ë“  Node(k8s-controlplane, k8s-node01, k8s-node02)ì— ë™ì¼í•˜ê²Œ ì§„í–‰í•©ë‹ˆë‹¤.  

ê° ë…¸ë“œë¡œ ssh ì ‘ì† í›„ ë‹¤ìŒ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ì„¸ìš”.  

> ìƒì„¸ ë‚´ìš©ì€ [Container Runtimes](https://kubernetes.io/docs/setup/production-environment/container-runtimes/)ë¥¼ ì°¸ì¡°.

#### 2.1. Network ì„¤ì •

[Network Plugin Requirements](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#network-plugin-requirements)ì— ë”°ë¼ iptables proxy ì„¤ì •ì„ í•©ë‹ˆë‹¤.  

ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.  

> ğŸ’» ëª…ë ¹ì–´
>```bash
>cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
>overlay
>br_netfilter
>EOF
>
>sudo modprobe overlay
>sudo modprobe br_netfilter
>
># sysctl params required by setup, params persist across reboots
>cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
>net.bridge.bridge-nf-call-iptables  = 1
>net.bridge.bridge-nf-call-ip6tables = 1
>net.ipv4.ip_forward                 = 1
>EOF
>
># Apply sysctl params without reboot
>sudo sysctl --system
>```

> ê´€ë ¨ ë¬¸ì„œ : [Install and configure prerequisites](https://kubernetes.io/docs/setup/production-environment/container-runtimes/#install-and-configure-prerequisites) 

---

#### 2.2. containerd ì„¤ì¹˜

containerdë¥¼ apt packageë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.  

> ğŸ’» ëª…ë ¹ì–´
>```bash
># Add Docker's official GPG key:
>sudo apt-get update
>sudo apt-get install -y ca-certificates curl gnupg
>sudo install -m 0755 -d /etc/apt/keyrings
>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
>sudo chmod a+r /etc/apt/keyrings/docker.gpg
>
># Add the repository to Apt sources:
>echo \
>  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
>  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
>  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
>sudo apt-get update
>sudo apt-get install -y containerd.io
>```

> ê´€ë ¨ ë¬¸ì„œ : [Getting started with containerd - Installing containerd - Option 2: From apt-get](https://github.com/containerd/containerd/blob/main/docs/getting-started.md#option-2-from-apt-get-or-dnf) , [Install Docker Engine on Ubuntu](https://docs.docker.com/engine/install/ubuntu/)

---

#### 2.3. containerd ì„¤ì •

systemdë¥¼ cgroup driverë¡œ ì‚¬ìš©í•˜ê³ , CRI Supportë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ containrdì˜ ì„¤ì •ì„ ë³€ê²½í•©ë‹ˆë‹¤.  

ë¨¼ì € config.toml íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤. (overwrite)  
> ğŸ’» ëª…ë ¹ì–´
>```bash
>containerd config default | sudo tee /etc/containerd/config.toml
>```
> containerd ì˜ default config.ë¥¼ config.toml íŒŒì¼ì— ê¸°ë¡

Containerdì˜ default config.ì—ì„œëŠ” `SystemdCgroup = false`ë¡œ ë˜ì–´ìˆê¸° ë•Œë¬¸ì— ì´ ë¶€ë¶„ì„ ë³€ê²½í•©ë‹ˆë‹¤.  
> ğŸ’» ëª…ë ¹ì–´
>```bash
>sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
>```

ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.  
- disabled_plugins ì— criê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šë‹¤.
- SystemdCgroup = true ( [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options] ë¶€ë¶„ )
```bash
$ sudo cat /etc/containerd/config.toml | grep disabled_plugins
disabled_plugins = []
$ sudo cat /etc/containerd/config.toml | grep SystemdCgroup
            SystemdCgroup = true
```

> ğŸ’» ëª…ë ¹ì–´
>```bash
>sudo cat /etc/containerd/config.toml | grep disabled_plugins
>```
>```bash
>sudo cat /etc/containerd/config.toml | grep SystemdCgroup
>```

ì„¤ì •ì„ ë³€ê²½í–ˆìœ¼ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì„œ containerd ë¥¼ ì¬ì‹œì‘í•©ë‹ˆë‹¤.
> ğŸ’» ëª…ë ¹ì–´
>```bash
>sudo systemctl restart containerd
>```

> ê´€ë ¨ ë¬¸ì„œ : [Configuring the systemd cgroup driver](https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd-systemd)

---

### 3. kubeadm, kubelet, kubectl ì„¤ì¹˜

ë‹¤ìŒ ì„¸ ê°œì˜ íŒ¨í‚¤ì§€ë¥¼ ëª¨ë“  ë…¸ë“œì— ì„¤ì¹˜í•©ë‹ˆë‹¤.  
- kubeadm : Kubernetes í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ë„êµ¬
- kubelet : Kubernetes node componentë¡œ Pod/Containerì˜ ë™ì‘ì„ ê´€ë¦¬
- kubectl: Kubernetes CLI ë„êµ¬

ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•´ì„œ ì„¸ ê°œì˜ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
> ì•„ë˜ ëª…ë ¹ì–´ëŠ” Kubernetes v1.29 ê²½ìš°ì…ë‹ˆë‹¤. ì„¤ì¹˜ ì‹œì ì— í•„ìš”í•œ ë²„ì ¼ì„ í™•ì¸ í›„ ì§„í–‰í•˜ì„¸ìš”.

> ğŸ’» ëª…ë ¹ì–´
>```bash
>sudo apt-get update
># apt-transport-https may be a dummy package; if so, you can skip that package
>sudo apt-get install -y apt-transport-https ca-certificates curl gpg
>
>curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
>
># This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list
>echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
>
>sudo apt-get update
>sudo apt-get install -y kubelet kubeadm kubectl
>sudo apt-mark hold kubelet kubeadm kubectl
>```

> ê´€ë ¨ ë¬¸ì„œ : [Installing kubeadm, kubelet and kubectl](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl)

---

### 4. Control-plane node êµ¬ì„±

**[ì£¼ì˜] ì´ ì ˆì°¨ëŠ” Control-plane nodeì—ì„œë§Œ ì§„í–‰í•©ë‹ˆë‹¤.**  

kubeadmì„ ì´ìš©í•´ì„œ Control-plane nodeì— í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.

ë¨¼ì € Control-plane nodeì˜ IP Address í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.  (AWS EC2ì¸ ê²½ìš° Private IPv4 addresses)
```bash
$ ip route show
default via 172.31.16.1 dev ens5 proto dhcp src 172.31.30.145 metric 100
...
```

> ğŸ’» ëª…ë ¹ì–´
> ```bash
>ip route show
...
> ìœ„ì™€ ê°™ì´ ì¶œë ¥ë˜ë©´ 172.31.30.145 ê°€ ì´ Nodeì˜ IP Address ì„.

ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ Control-plane nodeì— Control-plane componentë“¤ì„ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.  

> ğŸ’» ëª…ë ¹ì–´
>```bash
>sudo kubeadm init --apiserver-advertise-address=[API-SERVER IP ADDRESS] --pod-network-cidr=10.244.0.0/16
>```
> `--apiserver-advertise-address` : Control-plane nodeì˜ IP Address  
> `--pod-network-cidr` : ì‚¬ìš©í•  Network add-onì— ë”°ë¼ ì„¤ì •í•¨. (ìœ„ ì˜ˆì‹œëŠ” Flannel ì„ ìœ„í•œ êµ¬ì„±ì…ë‹ˆë‹¤.)

ì•„ë˜ëŠ” ì‹¤í–‰ê²°ê³¼ ì˜ˆì‹œì…ë‹ˆë‹¤.  
```bash
$ sudo kubeadm init --apiserver-advertise-address=172.31.30.145 --pod-network-cidr=10.244.0.0/16
[init] Using Kubernetes version: v1.29.0
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
W0112 08:14:02.746414    7047 checks.go:835] detected that the sandbox image "registry.k8s.io/pause:3.6" of the container runtime is inconsistent with that used by kubeadm. It is recommended that using "registry.k8s.io/pause:3.9" as the CRI sandbox image.
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [ip-172-31-30-145 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.31.30.145]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [ip-172-31-30-145 localhost] and IPs [172.31.30.145 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [ip-172-31-30-145 localhost] and IPs [172.31.30.145 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "super-admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Starting the kubelet
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
[apiclient] All control plane components are healthy after 7.002440 seconds
[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node ip-172-31-30-145 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node ip-172-31-30-145 as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]
[bootstrap-token] Using token: ev57z0.770ldkwdxb8if9bn
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.31.30.145:6443 --token ev57z0.770ldkw... \
	--discovery-token-ca-cert-hash sha256:3d98992e...
```

kubectl ì„¤ì •ì„ ìœ„í•´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
> ğŸ’» ëª…ë ¹ì–´
>```bash
>mkdir -p $HOME/.kube
>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
>sudo chown $(id -u):$(id -g) $HOME/.kube/config
>```
> [Tip] `kubectl` CLIë¥¼ í¸í•˜ê²Œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ [kubectl ìë™ ì™„ì„± í™œì„±í™”](https://kubernetes.io/ko/docs/tasks/tools/included/optional-kubectl-configs-bash-linux/#kubectl-%EC%9E%90%EB%8F%99-%EC%99%84%EC%84%B1-%ED%99%9C%EC%84%B1%ED%99%94)ë¥¼ ì ìš©í•˜ë©´ í¸í•©ë‹ˆë‹¤.

ë‹¤ìŒì€ pod network add-on ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤. ( ì•„ë˜ ì˜ˆì‹œëŠ” Flannel )

> ğŸ’» ëª…ë ¹ì–´
>```bash
>kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
>```

ì •ìƒì ìœ¼ë¡œ ì¤€ë¹„ê°€ ëœ ê²½ìš° ì•„ë˜ì™€ ê°™ì´ í‘œì‹œë©ë‹ˆë‹¤.  
```bash
$ kubectl get po -A
NAMESPACE      NAME                                       READY   STATUS    RESTARTS   AGE
kube-flannel   kube-flannel-ds-z97gc                      1/1     Running   0          2m1s
kube-system    coredns-76f75df574-276ns                   1/1     Running   0          5m3s
kube-system    coredns-76f75df574-swj5p                   1/1     Running   0          5m3s
kube-system    etcd-ip-172-31-26-107                      1/1     Running   0          5m17s
kube-system    kube-apiserver-ip-172-31-26-107            1/1     Running   0          5m17s
kube-system    kube-controller-manager-ip-172-31-26-107   1/1     Running   0          5m17s
kube-system    kube-proxy-x6zmg                           1/1     Running   0          5m3s
kube-system    kube-scheduler-ip-172-31-26-107            1/1     Running   0          5m18s
```

> ğŸ’» ëª…ë ¹ì–´
>```bash
>kubectl get po -A
>```

ì—¬ê¸°ê¹Œì§€ í•˜ë©´ Control-plane nodeëŠ” ì¤€ë¹„ê°€ ëìŠµë‹ˆë‹¤.  
ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ê¸° ì „ì— API Server ì ‘ê·¼ì„ ìœ„í•´ì„œ Control-plane nodeì˜ Security Groupì— ë‹¤ìŒ ê·œì¹™ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.  
| Type | Protocol | Port range | Source |
| --- | --- | --- | --- |
| Custom TCP | TCP | 6443 | 172.31.0.0/16 |
> Sourceì˜ IP RangeëŠ” (Worker) nodeì˜ IP Range ì…ë‹ˆë‹¤.




> ê´€ë ¨ ë¬¸ì„œ : [Initializing your control-plane node](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#initializing-your-control-plane-node)   
> ê´€ë ¨ ë¬¸ì„œ : [kubeadm init](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/)   
> ê´€ë ¨ ë¬¸ì„œ : [Deploying flannel manually](https://github.com/flannel-io/flannel?tab=readme-ov-file#deploying-flannel-manually)

---

### 5. (Worker) node êµ¬ì„±

**[ì£¼ì˜] ì´ ì ˆì°¨ëŠ” (Worker) nodeì—ì„œë§Œ ì§„í–‰í•©ë‹ˆë‹¤.**  

kubeadmì„ ì´ìš©í•´ì„œ (Worker) nodeì— í•„ìš”í•œ êµ¬ì„±ì„ í•˜ê³ , K8s clusterì— Join ì‹œí‚µë‹ˆë‹¤.  

ì• ì ˆì°¨ì—ì„œ ìƒì„±ëœ `kubeadm join ...` ëª…ë ¹ì–´ë¥¼ ì €ì¥í•´ ë‘ì—ˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.  
ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´
- api-server-endpoint  
- token  
- discovery-token-ca-cert-hash  
ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.  

**Control-plane node**ì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ í™•ì…í•©ë‹ˆë‹¤.  

(1) api-server-endpoint
```bash
$ kubectl cluster-info
Kubernetes control plane is running at https://172.31.30.145:6443
CoreDNS is running at https://172.31.30.145:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
```
> `172.31.30.145:6443` ì´ API Serverì˜ endpoint ì…ë‹ˆë‹¤.

> ğŸ’» ëª…ë ¹ì–´
>```bash
>kubectl cluster-info
>```


(2) token
```bash
$ kubeadm token list
TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS
ev57z0.770ldkw...   21h         2024-01-16T05:07:18Z   authentication,signing   The default bootstrap token generated by 'kubeadm init'.   system:bootstrappers:kubeadm:default-node-token
```
> `ev57z0.770ldkw...` ì´ token name ì…ë‹ˆë‹¤.

> ğŸ’» ëª…ë ¹ì–´
>```bash
>kubeadm token list
>```


(3) discovery-token-ca-cert-hash
```bash
$ openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'
3d98992e...
```
> `3d98992e...` ì´ CA Cert ì˜ Hash ì…ë‹ˆë‹¤.

> ğŸ’» ëª…ë ¹ì–´
>```bash
>openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'
>```


ìœ„ì˜ ì •ë³´ë¥¼ ì¡°í•©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì´ `kubeadm join` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.  
```bash
$ sudo kubeadm join 172.31.30.145:6443 --token ev57z0.770ldkw... --discovery-token-ca-cert-hash sha256:3d98992e...

[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
```

> ğŸ’» ëª…ë ¹ì–´
>```bash
>sudo kubeadm join [API-SERVER Endpoint] --token [TOKEN-NAME] --discovery-token-ca-cert-hash sha256:[CA-CERT Hash]
>```
> ì£¼ì˜ : `kubeadm join` ëª…ë ¹ì–´ëŠ” Control-plane nodeê°€ ì•„ë‹Œ, (Worker) node ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.


Join í›„ì— kubectlì„ ì´ìš©í•´ì„œ Nodeë¥¼ ì¡°íšŒí•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì¡°íšŒë©ë‹ˆë‹¤.  
```bash
$ kubectl get nodes -o wide
NAME               STATUS   ROLES           AGE    VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION    CONTAINER-RUNTIME
ip-172-31-30-145   Ready    <none>          10s    v1.29.0   172.31.30.145   <none>        Ubuntu 20.04.6 LTS   5.15.0-1048-aws   containerd://1.6.26
ip-172-31-25-27    Ready    <none>          18s    v1.29.0   172.31.25.27    <none>        Ubuntu 20.04.6 LTS   5.15.0-1048-aws   containerd://1.6.26
ip-172-31-29-238   Ready    control-plane   175m   v1.29.0   172.31.29.238   <none>        Ubuntu 20.04.6 LTS   5.15.0-1048-aws   containerd://1.6.26
```

> ğŸ’» ëª…ë ¹ì–´
>```bash
>kubectl get nodes -o wide
>```
> í•œ ê°œì˜ Control-plane nodeì™€ ë‘ ê°œì˜ (Worker) node ê°€ í™•ì¸ë¨.



> ê´€ë ¨ ë¬¸ì„œ : [kubeadm join](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-join/)

---

### 6. Helm ì„¤ì¹˜

Kubernetes package managerì¸ Helmì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.  
kubectl CLIë¥¼ ìœ„í•œ ì„¤ì •ì´ ëœ ê³³(ì•ì˜ ê³¼ì •ëŒ€ë¡œ ì§„í–‰í•˜ì…¨ë‹¤ë©´ Control-plane node)ì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì¹˜í•©ë‹ˆë‹¤.  

> ğŸ’» ëª…ë ¹ì–´
>```bash
>curl -LO https://get.helm.sh/helm-v3.13.3-linux-amd64.tar.gz
>tar -zxvf helm-v3.13.3-linux-amd64.tar.gz
>sudo mv linux-amd64/helm /usr/local/bin/helm
>```
> ì„¤ì¹˜ ì‹œì ‘ì˜ ë¦´ë¦¬ì¦ˆ í™•ì¸ì€ [Helm releases](https://github.com/helm/helm/releases)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

ì„¤ì¹˜ í™•ì¸ì€ ì•„ë˜ì™€ ê°™ì´ í•´ë³´ì‹œë©´ ë©ë‹ˆë‹¤.  
```bash
$ helm version
version.BuildInfo{Version:"v3.13.3", GitCommit:"c8b948945e52abba22ff885446a1486cb5fd3474", GitTreeState:"clean", GoVersion:"go1.20.11"}
```

> ğŸ’» ëª…ë ¹ì–´
>```bash
>helm version
>```

> ê´€ë ¨ ë¬¸ì„œ : [Installing Helm  - From the binary releases ](https://helm.sh/docs/intro/install/#from-the-binary-releases)

---

### 7. Ingress controller ì„¤ì¹˜ ë° êµ¬ì„±

Ingress controllerë¡œ Nginxë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.  

> ğŸ’» ëª…ë ¹ì–´
>```bash
>helm install ingress-nginx ingress-nginx \
>  --repo https://kubernetes.github.io/ingress-nginx \
>  --namespace ingress-nginx --create-namespace \
>  --set controller.service.type=NodePort \
>  --set controller.service.nodePorts.http=30000 \
>  --set controller.service.nodePorts.https=30001
>```
> ingress-nginx helm chartë¥¼ ì´ìš©í•˜ê³ , Service typeì€ NodePort(HTTP:30000, HTTPS:30001)ë¡œ ì„¤ì • í–ˆìŠµë‹ˆë‹¤.


ì´ êµ¬ì„±ì€ Ingress-Nginx Controllerì˜ Bare-metal êµ¬ì„±ì—ì„œ [Over a NodePort Service](https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#over-a-nodeport-service) ë°©ë²•ì„ ì‚¬ìš©í•œ ê²ƒì…ë‹ˆë‹¤.  
Load balancing êµ¬ì„±ì€ ì—¬ëŸ¬ê°€ì§€ ë°©ë²•ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, êµ¬ì¶•í•˜ëŠ” í™˜ê²½ì— ë§ê²Œ êµ¬ì„±í•˜ì‹œë©´ ë©ë‹ˆë‹¤.  

ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´ ì•„ë˜ì™€ ê°™ì´ `ingress-nginx` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì™€ ë¦¬ì†ŒìŠ¤ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤.  
```bash
$ helm ls -n ingress-nginx
NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                   APP VERSION
ingress-nginx   ingress-nginx   1               2024-01-18 04:09:58.730337499 +0000 UTC deployed        ingress-nginx-4.9.0     1.9.5      

$ kubectl get all -n ingress-nginx
NAME                                            READY   STATUS    RESTARTS   AGE
pod/ingress-nginx-controller-6c84576bbd-x487j   1/1     Running   0          41s

NAME                                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
service/ingress-nginx-controller             NodePort    10.107.129.131   <none>        80:30000/TCP,443:30001/TCP   41s
service/ingress-nginx-controller-admission   ClusterIP   10.106.188.41    <none>        443/TCP                      41s

NAME                                       READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/ingress-nginx-controller   1/1     1            1           41s

NAME                                                  DESIRED   CURRENT   READY   AGE
replicaset.apps/ingress-nginx-controller-6c84576bbd   1         1         1       41s
```

> ğŸ’» ëª…ë ¹ì–´
>```bash
>helm ls -n ingress-nginx
>```
>```bash
>kubectl get all -n ingress-nginx
>```
ì„¤ì¹˜ í›„ NodePortë¥¼ íŠ¹ì • í¬íŠ¸ë¡œ ë³€ê²½í•˜ë ¤ë©´ [kubectl edit](https://kubernetes.io/docs/reference/kubectl/generated/kubectl_edit/) ëª…ë ¹ì–´ë¥¼ ì´ìš©í•˜ì—¬ ë³€ê²½í•©ë‹ˆë‹¤.  

ì‚­ì œëŠ” ë‹¤ìŒê³¼ ê°™ì´ í•©ë‹ˆë‹¤.  
```bash
helm uninstall ingress-nginx --namespace ingress-nginx
kubectl delete namespaces ingress-nginx
```

> ğŸ’» ëª…ë ¹ì–´
>```bash
>helm uninstall ingress-nginx --namespace ingress-nginx
>```
>```bash
>kubectl delete namespaces ingress-nginx
>```

> ê´€ë ¨ ë¬¸ì„œ : [Ingress Controllers](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/)  
> ê´€ë ¨ ë¬¸ì„œ : [Ingress-Nginx Controller - Installation Guide - Quick start](https://kubernetes.github.io/ingress-nginx/deploy/#quick-start)  
> ê´€ë ¨ ë¬¸ì„œ : [Ingress-Nginx Controller - Bare-metal considerations](https://kubernetes.github.io/ingress-nginx/deploy/baremetal/)  
> ê´€ë ¨ ë¬¸ì„œ : [Ingress-Nginx Helm chart](https://github.com/kubernetes/ingress-nginx/tree/main/charts/ingress-nginx)

---

### 8. Storage Class êµ¬ì„±

> [ì‚¬ì „ì¡°ê±´] NFS Serverê°€ êµ¬ì„±ë˜ì–´ ìˆì–´ì•¼ í•¨.

ë¯¸ë¦¬ ì¤€ë¹„ëœ NFS Serverì˜ Storageë¥¼ Dynamic Volume provisioningì˜ì—­ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ Storage Classë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.  
ë¨¼ì €, ì›Œí¬ë¡œë“œê°€ ì‹¤í–‰ë  ë…¸ë“œ( (worker) node )ì— NFS Clientë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.  

> ğŸ’» ëª…ë ¹ì–´
>```bash
>sudo apt-get update
>sudo apt-get install -y nfs-common
>```

ê·¸ ë‹¤ìŒì€ NFS Serverì—ì„œ ê³µìœ ëœ ë””ë ‰í† ë¦¬ì˜ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.  
ì´ ì˜ì—­ì€ ë¯¸ë¦¬ ì¤€ë¹„ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.  

```bash
$ showmount -e 172.31.26.107
Export list for 172.31.26.107:
/data/k8s-volume 172.31.16.0/20
```
> ìœ„ ì˜ˆì‹œëŠ” 172.31.26.107 ì— NFS Serverê°€ êµ¬ì„±ë˜ì–´ ìˆëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. /data/k8s-volume ë””ë ‰í† ë¦¬ê°€ Volume ì˜ì—­ìœ¼ë¡œ ì‚¬ìš©ë˜ê³  172.31.16.0/20ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ êµ¬ì„±ì…ë‹ˆë‹¤.

> ğŸ’» ëª…ë ¹ì–´
>```bash
>showmount -e [NFS-SERVER IP ADDRESS]
>```


ì´ì œ NFS Subdir External Provisioner ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
```bash
$ helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/
$ helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
    --create-namespace --namespace nfs-provisioner \
    --set nfs.server=172.31.26.107 \
    --set nfs.path=/data/k8s-volume \
    --set storageClass.defaultClass=true
```

> ğŸ’» ëª…ë ¹ì–´
>```bash
>helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/
>```
>```bash
>helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \
>    --create-namespace --namespace nfs-provisioner \
>    --set nfs.server=[NFS-SERVER IP ADDRESS] \
>    --set nfs.path=[NFS-SERVER VOLUME PATH] \
>    --set storageClass.defaultClass=true
>```
> nfs.server(NFS Serverì˜ IP Address)ì™€ nfs.path(NFS Serverì˜ Volume ì˜ì—­)ëŠ” ì•ì„œ í™•ì¸í•œ ì •ë³´ë¥¼ ì°¸ì¡°í•˜ì—¬ ì„¤ì •í•©ë‹ˆë‹¤.

ì„¤ì¹˜ í›„ í™•ì¸ì€ ì•„ë˜ì™€ ê°™ì´ í•©ë‹ˆë‹¤.
```bash
$ kubectl get storageclasses
NAME                   PROVISIONER                                     RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs-client (default)   cluster.local/nfs-subdir-external-provisioner   Delete          Immediate           true                   33d
$ kubectl describe storageclasses nfs-client 
Name:                  nfs-client
IsDefaultClass:        Yes
Annotations:           meta.helm.sh/release-name=nfs-subdir-external-provisioner,meta.helm.sh/release-namespace=nfs-provisioner,storageclass.kubernetes.io/is-default-class=true
Provisioner:           cluster.local/nfs-subdir-external-provisioner
Parameters:            archiveOnDelete=true
AllowVolumeExpansion:  True
MountOptions:          <none>
ReclaimPolicy:         Delete
VolumeBindingMode:     Immediate
Events:                <none>
```

> ğŸ’» ëª…ë ¹ì–´
>```bash
>kubectl get storageclasses
>```
>```bash
>kubectl describe storageclasses nfs-client
>```

> ê´€ë ¨ ë¬¸ì„œ : [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/)  
> ê´€ë ¨ ë¬¸ì„œ : [nfs-subdir-external-provisioner](https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner)  
